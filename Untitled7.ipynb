{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flair'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-06e00744b05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mELMoEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# init embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mELMoEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flair'"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import ELMoEmbeddings\n",
    "\n",
    "# init embedding\n",
    "embedding = ELMoEmbeddings()\n",
    "\n",
    "# create a sentence\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# embed words in sentence\n",
    "embedding.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/49/a812ed93088ba9519cbb40eb9f52341694b31cfa126bfddcd9db3761f3ac/flair-0.6.1.post1-py3-none-any.whl (337kB)\n",
      "\u001b[K     |████████████████████████████████| 337kB 9.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.26.0 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/bc/857fff709f7ce9eabdc502d6fa71f4b7e964200b1bcd00f0a2f59667d1bf/tqdm-4.53.0-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 17.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mpld3==0.3 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
      "\u001b[K     |████████████████████████████████| 798kB 32.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sqlitedict>=1.6.0 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
      "Collecting janome (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
      "\u001b[K     |████████████████████████████████| 19.7MB 6.9MB/s eta 0:00:01        | 921kB 8.2MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/e0/57edbab017a204e9f39448c1717292437a45b5f7cf3a9dbf4a9c026b03c5/sentencepiece-0.1.94.tar.gz (507kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 26.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tabulate (from flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/c4/f4/770ae9385990f5a19a91431163d262182d3203662ea2b5739d0fcfc080f1/tabulate-0.8.7-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from flair) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from flair) (2.8.1)\n",
      "Collecting regex (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/ad/e0a6ea246c70fe549d8ef4a4632e66cccbdaab4830b04735f44144ed9308/regex-2020.11.13-cp36-cp36m-manylinux2010_x86_64.whl (666kB)\n",
      "\u001b[K     |████████████████████████████████| 675kB 9.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting transformers>=3.0.0 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 16.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting segtok>=1.5.7 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
      "Collecting deprecated>=1.2.4 (from flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
      "Collecting konoha<5.0.0,>=4.0.0 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/01/47358efec5396fc80f98273c42cbdfe7aab056252b07884ffcc0f118978f/konoha-4.6.2-py3-none-any.whl\n",
      "Collecting scikit-learn>=0.21.3 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8MB 6.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hyperopt>=0.1.1 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/07/bd524635d218adae139be320eeac87fb4fbbd45c63b0bd58930c9e91f1fc/hyperopt-0.2.5-py2.py3-none-any.whl (965kB)\n",
      "\u001b[K     |████████████████████████████████| 972kB 23.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langdetect (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
      "\u001b[K     |████████████████████████████████| 983kB 14.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from flair) (1.3.1)\n",
      "Collecting gdown (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/50/21/92c3cfe56f5c0647145c4b0083d0733dd4890a057eb100a8eeddf949ffe9/gdown-3.12.2.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ftfy (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 6.1MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting gensim>=3.4.0 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2MB 1.6MB/s eta 0:00:011    |██▉                             | 2.1MB 31.3MB/s eta 0:00:01MB/s eta 0:00:01     |██████████████████████████████▉ | 23.3MB 1.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lxml (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/28/0b761b64ecbd63d272ed0e7a6ae6e4402fc37886b59181bfdf274424d693/lxml-4.6.1-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5MB 6.8MB/s eta 0:00:01ta 0:00:01\n",
      "\u001b[?25hCollecting bpemb>=0.3.2 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/91/77/3f0f53856e86af32b1d3c86652815277f7b5f880002584eb30db115b6df5/bpemb-0.3.2-py3-none-any.whl\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (2020.6.20)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from python-dateutil>=2.6.1->flair) (1.15.0)\n",
      "Collecting packaging (from transformers>=3.0.0->flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/46/19/c5ab91b1b05cfe63cccd5cfc971db9214c6dd6ced54e33c30d5af1d2bc43/packaging-20.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: protobuf in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from transformers>=3.0.0->flair) (3.13.0)\n",
      "Collecting tokenizers==0.9.3 (from transformers>=3.0.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 14.4MB/s eta 0:00:01████████████  | 2.7MB 14.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock (from transformers>=3.0.0->flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/93/83/71a2ee6158bb9f39a90c0dea1637f81d5eef866e188e1971a1b1ab01a35a/filelock-3.0.12-py3-none-any.whl\n",
      "Collecting dataclasses; python_version < \"3.7\" (from transformers>=3.0.0->flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from transformers>=3.0.0->flair) (2.24.0)\n",
      "Collecting sacremoses (from transformers>=3.0.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt<2,>=1.10 (from deprecated>=1.2.4->flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/82/f7/e43cefbe88c5fd371f4cf0cf5eb3feccd07515af9fd6cf7dbf1d1793a797/wrapt-1.12.1.tar.gz\n",
      "Collecting overrides==3.0.0 (from konoha<5.0.0,>=4.0.0->flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n",
      "Collecting joblib>=0.11 (from scikit-learn>=0.21.3->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl (301kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 34.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn>=0.21.3->flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from scikit-learn>=0.21.3->flair) (1.5.3)\n",
      "Collecting future (from hyperopt>=0.1.1->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 8.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.2 (from hyperopt>=0.1.1->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/cd/dc52755d30ba41c60243235460961fc28022e5b6731f16c268667625baea/networkx-2.5-py3-none-any.whl (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 8.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle (from hyperopt>=0.1.1->flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: wcwidth in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from ftfy->flair) (0.2.5)\n",
      "Collecting smart-open>=1.8.1 (from gensim>=3.4.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/aa/eae69b4a86ed401625820a202272f3c0cbd8eade5abdbe248396aa5a837d/smart_open-4.0.0.tar.gz (106kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 6.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from protobuf->transformers>=3.0.0->flair) (49.6.0.post20201009)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests->transformers>=3.0.0->flair) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests->transformers>=3.0.0->flair) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests->transformers>=3.0.0->flair) (3.0.4)\n",
      "Collecting click (from sacremoses->transformers>=3.0.0->flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from networkx>=2.2->hyperopt>=0.1.1->flair) (4.4.2)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/81/d0/d7/d9983facc6f2775411803e0e2d30ebf98efbf2fc6e57701e09\n",
      "Successfully built gdown\n",
      "Building wheels for collected packages: mpld3, sqlitedict, sentencepiece, segtok, langdetect, ftfy, sacremoses, wrapt, overrides, future, smart-open\n",
      "  Building wheel for mpld3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
      "  Building wheel for sentencepiece (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Complete output from command /home/jupyterlab/conda/envs/python/bin/python -u -c 'import setuptools, tokenize;__file__='\"'\"'/tmp/pip-install-g7erltvo/sentencepiece/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-7l5dkqgg --python-tag cp36:\u001b[0m\n",
      "\u001b[31m  ERROR: running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.6\n",
      "  creating build/lib.linux-x86_64-3.6/sentencepiece\n",
      "  copying src/sentencepiece/__init__.py -> build/lib.linux-x86_64-3.6/sentencepiece\n",
      "  copying src/sentencepiece/sentencepiece_model_pb2.py -> build/lib.linux-x86_64-3.6/sentencepiece\n",
      "  copying src/sentencepiece/sentencepiece_pb2.py -> build/lib.linux-x86_64-3.6/sentencepiece\n",
      "  running build_ext\n",
      "  /bin/sh: 1: pkg-config: not found\n",
      "  Cloning into 'sentencepiece'...\n",
      "  Note: checking out '8336bbd0c1cfba02a879afe625bf1ddaf7cd93c5'.\n",
      "  \n",
      "  You are in 'detached HEAD' state. You can look around, make experimental\n",
      "  changes and commit them, and you can discard any commits you make in this\n",
      "  state without impacting any branches by performing another checkout.\n",
      "  \n",
      "  If you want to create a new branch to retain commits you create, you may\n",
      "  do so (now or later) by using -b with the checkout command again. Example:\n",
      "  \n",
      "    git checkout -b <new-branch-name>\n",
      "  \n",
      "  -- VERSION: 0.1.94\n",
      "  -- The C compiler identification is GNU 7.2.0\n",
      "  -- The CXX compiler identification is GNU 7.2.0\n",
      "  -- Check for working C compiler: /home/jupyterlab/conda/envs/python/bin/x86_64-conda_cos6-linux-gnu-cc\n",
      "  -- Check for working C compiler: /home/jupyterlab/conda/envs/python/bin/x86_64-conda_cos6-linux-gnu-cc -- works\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- Check for working CXX compiler: /home/jupyterlab/conda/envs/python/bin/x86_64-conda_cos6-linux-gnu-c++\n",
      "  -- Check for working CXX compiler: /home/jupyterlab/conda/envs/python/bin/x86_64-conda_cos6-linux-gnu-c++ -- works\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- Looking for pthread.h\n",
      "  -- Looking for pthread.h - found\n",
      "  -- Looking for pthread_create\n",
      "  -- Looking for pthread_create - not found\n",
      "  -- Looking for pthread_create in pthreads\n",
      "  -- Looking for pthread_create in pthreads - not found\n",
      "  -- Looking for pthread_create in pthread\n",
      "  -- Looking for pthread_create in pthread - found\n",
      "  -- Found Threads: TRUE\n",
      "  -- Not Found TCMalloc: TCMALLOC_LIB-NOTFOUND\n",
      "  -- Configuring done\n",
      "  -- Generating done\n",
      "  -- Build files have been written to: /tmp/pip-install-g7erltvo/sentencepiece/bundled/sentencepiece/build\n",
      "  Scanning dependencies of target sentencepiece-static\n",
      "  Scanning dependencies of target sentencepiece_train-static\n",
      "  [  3%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/unicode_script.cc.o\n",
      "  [  3%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/bytestream.cc.o\n",
      "  [  4%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/builder.cc.o\n",
      "  [  6%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/arena.cc.o\n",
      "  [  8%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/arenastring.cc.o\n",
      "  [  9%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/trainer_factory.cc.o\n",
      "  [ 11%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_message_table_driven_lite.cc.o\n",
      "  [ 13%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/extension_set.cc.o\n",
      "  [ 14%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/common.cc.o\n",
      "  [ 16%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/unigram_model_trainer.cc.o\n",
      "  [ 18%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/coded_stream.cc.o\n",
      "  [ 19%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/trainer_interface.cc.o\n",
      "  [ 21%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/bpe_model_trainer.cc.o\n",
      "  [ 22%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_message_util.cc.o\n",
      "  [ 24%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/word_model_trainer.cc.o\n",
      "  [ 26%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/char_model_trainer.cc.o\n",
      "  [ 27%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/implicit_weak_message.cc.o\n",
      "  [ 29%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/sentencepiece_trainer.cc.o\n",
      "  [ 31%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/int128.cc.o\n",
      "  [ 32%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/io_win32.cc.o\n",
      "  [ 34%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/message_lite.cc.o\n",
      "  [ 36%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/repeated_field.cc.o\n",
      "  [ 37%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/status.cc.o\n",
      "  [ 39%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/statusor.cc.o\n",
      "  [ 40%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/stringpiece.cc.o\n",
      "  [ 42%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/pretokenizer_for_training.cc.o\n",
      "  [ 44%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/structurally_valid.cc.o\n",
      "  [ 45%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/stringprintf.cc.o\n",
      "  [ 47%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/strutil.cc.o\n",
      "  [ 49%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/time.cc.o\n",
      "  [ 50%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/wire_format_lite.cc.o\n",
      "  [ 52%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream.cc.o\n",
      "  [ 54%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/builtin_pb/sentencepiece.pb.cc.o\n",
      "  [ 55%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc.o\n",
      "  [ 57%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/builtin_pb/sentencepiece_model.pb.cc.o\n",
      "  [ 59%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/bpe_model.cc.o\n",
      "  [ 60%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/char_model.cc.o\n",
      "  [ 62%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/error.cc.o\n",
      "  [ 63%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/filesystem.cc.o\n",
      "  [ 65%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/model_factory.cc.o\n",
      "  [ 67%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/init.cc.o\n",
      "  [ 68%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/model_interface.cc.o\n",
      "  [ 70%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/normalizer.cc.o\n",
      "  [ 72%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/sentencepiece_processor.cc.o\n",
      "  [ 73%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/unigram_model.cc.o\n",
      "  [ 75%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/util.cc.o\n",
      "  [ 77%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/word_model.cc.o\n",
      "  [ 78%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/absl/strings/string_view.cc.o\n",
      "  [ 80%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/absl/flags/flag.cc.o\n",
      "  [ 81%] Linking CXX static library libsentencepiece.a\n",
      "  [ 81%] Built target sentencepiece-static\n",
      "  Scanning dependencies of target spm_export_vocab\n",
      "  Scanning dependencies of target spm_decode\n",
      "  Scanning dependencies of target spm_encode\n",
      "  [ 83%] Building CXX object src/CMakeFiles/spm_export_vocab.dir/spm_export_vocab_main.cc.o\n",
      "  [ 85%] Building CXX object src/CMakeFiles/spm_decode.dir/spm_decode_main.cc.o\n",
      "  [ 86%] Building CXX object src/CMakeFiles/spm_encode.dir/spm_encode_main.cc.o\n",
      "  [ 88%] Linking CXX static library libsentencepiece_train.a\n",
      "  [ 88%] Built target sentencepiece_train-static\n",
      "  Scanning dependencies of target spm_normalize\n",
      "  Scanning dependencies of target spm_train\n",
      "  [ 90%] Building CXX object src/CMakeFiles/spm_normalize.dir/spm_normalize_main.cc.o\n",
      "  [ 91%] Building CXX object src/CMakeFiles/spm_train.dir/spm_train_main.cc.o\n",
      "  [ 93%] Linking CXX executable spm_export_vocab\n",
      "  [ 93%] Built target spm_export_vocab\n",
      "  [ 95%] Linking CXX executable spm_decode\n",
      "  [ 95%] Built target spm_decode\n",
      "  [ 96%] Linking CXX executable spm_encode\n",
      "  [ 96%] Built target spm_encode\n",
      "  [ 98%] Linking CXX executable spm_normalize\n",
      "  [100%] Linking CXX executable spm_train\n",
      "  [100%] Built target spm_normalize\n",
      "  [100%] Built target spm_train\n",
      "  [ 65%] Built target sentencepiece-static\n",
      "  [ 68%] Built target spm_export_vocab\n",
      "  [ 86%] Built target sentencepiece_train-static\n",
      "  [ 90%] Built target spm_encode\n",
      "  [ 93%] Built target spm_normalize\n",
      "  [ 96%] Built target spm_decode\n",
      "  [100%] Built target spm_train\n",
      "  Install the project...\n",
      "  -- Install configuration: \"\"\n",
      "  -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/lib/pkgconfig/sentencepiece.pc\n",
      "  -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/lib/libsentencepiece.a\n",
      "  -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/lib/libsentencepiece_train.a\n",
      "  -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/bin/spm_encode\n",
      "  -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/bin/spm_decode\n",
      "  -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/bin/spm_normalize\n",
      "  -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/bin/spm_train\n",
      "  -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/bin/spm_export_vocab\n",
      "  -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/include/sentencepiece_trainer.h\n",
      "  -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/include/sentencepiece_processor.h\n",
      "  env: ‘pkg-config’: No such file or directory\n",
      "  Failed to find sentencepiece pkg-config\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for sentencepiece\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for sentencepiece\n",
      "  Building wheel for segtok (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
      "  Building wheel for ftfy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/b1/c2/ed/d62208260edbd3fa7156545c00ef966f45f2063d0a84f8208a\n",
      "  Building wheel for overrides (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/5b/01/5e/7cd4c5ac06c976e3e27cc4bee460c3cf6ed01b24b19783c1a0\n",
      "Successfully built mpld3 sqlitedict segtok langdetect ftfy sacremoses wrapt overrides future smart-open\n",
      "Failed to build sentencepiece\n",
      "\u001b[31mERROR: transformers 3.5.1 has requirement sentencepiece==0.1.91, but you'll have sentencepiece 0.1.94 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tqdm, mpld3, sqlitedict, janome, sentencepiece, tabulate, regex, packaging, tokenizers, filelock, dataclasses, click, joblib, sacremoses, transformers, segtok, wrapt, deprecated, overrides, konoha, threadpoolctl, scikit-learn, future, networkx, cloudpickle, hyperopt, langdetect, gdown, ftfy, smart-open, gensim, lxml, bpemb, flair\n",
      "  Running setup.py install for sentencepiece ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Complete output from command /home/jupyterlab/conda/envs/python/bin/python -u -c 'import setuptools, tokenize;__file__='\"'\"'/tmp/pip-install-g7erltvo/sentencepiece/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-2vxldf1s/install-record.txt --single-version-externally-managed --compile:\u001b[0m\n",
      "\u001b[31m    ERROR: running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/sentencepiece\n",
      "    copying src/sentencepiece/__init__.py -> build/lib.linux-x86_64-3.6/sentencepiece\n",
      "    copying src/sentencepiece/sentencepiece_model_pb2.py -> build/lib.linux-x86_64-3.6/sentencepiece\n",
      "    copying src/sentencepiece/sentencepiece_pb2.py -> build/lib.linux-x86_64-3.6/sentencepiece\n",
      "    running build_ext\n",
      "    /bin/sh: 1: pkg-config: not found\n",
      "    mkdir: cannot create directory ‘bundled’: File exists\n",
      "    fatal: destination path 'sentencepiece' already exists and is not an empty directory.\n",
      "    fatal: destination path 'sentencepiece' already exists and is not an empty directory.\n",
      "    mkdir: cannot create directory ‘build’: File exists\n",
      "    -- VERSION: 0.1.94\n",
      "    -- Not Found TCMalloc: TCMALLOC_LIB-NOTFOUND\n",
      "    -- Configuring done\n",
      "    -- Generating done\n",
      "    -- Build files have been written to: /tmp/pip-install-g7erltvo/sentencepiece/bundled/sentencepiece/build\n",
      "    [ 18%] Built target sentencepiece_train-static\n",
      "    [ 83%] Built target sentencepiece-static\n",
      "    [ 86%] Built target spm_encode\n",
      "    [ 90%] Built target spm_normalize\n",
      "    [ 93%] Built target spm_export_vocab\n",
      "    [ 96%] Built target spm_train\n",
      "    [100%] Built target spm_decode\n",
      "    [ 65%] Built target sentencepiece-static\n",
      "    [ 68%] Built target spm_export_vocab\n",
      "    [ 86%] Built target sentencepiece_train-static\n",
      "    [ 90%] Built target spm_encode\n",
      "    [ 93%] Built target spm_normalize\n",
      "    [ 96%] Built target spm_decode\n",
      "    [100%] Built target spm_train\n",
      "    Install the project...\n",
      "    -- Install configuration: \"\"\n",
      "    -- Up-to-date: /tmp/pip-install-g7erltvo/sentencepiece/bundled/lib/pkgconfig/sentencepiece.pc\n",
      "    -- Up-to-date: /tmp/pip-install-g7erltvo/sentencepiece/bundled/lib/libsentencepiece.a\n",
      "    -- Up-to-date: /tmp/pip-install-g7erltvo/sentencepiece/bundled/lib/libsentencepiece_train.a\n",
      "    -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/bin/spm_encode\n",
      "    -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/bin/spm_decode\n",
      "    -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/bin/spm_normalize\n",
      "    -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/bin/spm_train\n",
      "    -- Installing: /tmp/pip-install-g7erltvo/sentencepiece/bundled/bin/spm_export_vocab\n",
      "    -- Up-to-date: /tmp/pip-install-g7erltvo/sentencepiece/bundled/include/sentencepiece_trainer.h\n",
      "    -- Up-to-date: /tmp/pip-install-g7erltvo/sentencepiece/bundled/include/sentencepiece_processor.h\n",
      "    env: ‘pkg-config’: No such file or directory\n",
      "    Failed to find sentencepiece pkg-config\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command \"/home/jupyterlab/conda/envs/python/bin/python -u -c 'import setuptools, tokenize;__file__='\"'\"'/tmp/pip-install-g7erltvo/sentencepiece/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-2vxldf1s/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-install-g7erltvo/sentencepiece/\u001b[0m\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
